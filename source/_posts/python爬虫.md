---
title: python爬虫了解
date: 2017-07-19 12:52:14
tags: [python, scrpy]
category: python
---



# python爬虫
1.熟悉python基本语法

一：爬虫常用的方式

<!-- more -->

2.如何抓取html页面：

​    http请求的处理，urllib、urllib2、request

<u>3</u>.解析服务器响应的内容

​    re、xpath、Beautisoup4（bs4）、jsonpath、pyquery等

4.如何采集动态html、验证码的处理

​    

5.scrapy框架：（Scrapy，Pyspider)

​        高定制性高性能 （异步网络框架twisted），所以数据下载速度很快，提供了数据存储，数据已下载，提取规则等组件

6.分布式策略：

​    scrapy-redis，在scrapy的基础上添加了一套以Redis数据库为核心的组件。

​             让Scrapy框架支持分布式的功能，主要在Redis理做，请求指纹去重、请求分配、数据临时存储

7.爬虫、反爬虫 、反反爬虫

​    user-agent 、代理、验证码、动态数据加载、加密数据。

二：根据使用情况：通用爬虫、聚焦爬虫

1.通用爬虫：搜索引擎的爬虫系统。

​       1. 目标： 就是尽可能的把互联网上的所有网页下载下来，放到本地服务器里形成备份

​        再对这些网页做相关处理（提取关键字、去掉广告），最后提供一个用户检索借口

​        2.抓取流程：

​                1.首先选取一部分已有的URL，把这些URL放到待爬取队列。

​                2.从队列里取出这些url，然后解析DNS得到主机ip，然后去这个ip对应的服务器里下载html页面，

​                    之后把这个爬过的urll放入已爬取队列。

​                3.分析这些网页内容，找到网页里其他网页链接，继续执行第二部，直到结束。

​        3.搜索引擎如何获取一个新网站的URL：

​                1.主动向搜索引擎提交

​                2.在其他网站设置外链

​                3.搜索引擎会和DNS服务商进行合作，可以快速收录新网站

​        4.通用爬虫并不是万物皆可爬，它也需要遵守一些规则：

​            Robots协议： 协议会指明通用爬虫可爬取的权限

​            RObots.txt 并不是所有爬虫都遵守，一般只有大型的搜索引擎才会遵守。

​            个人写的爬虫，不需要官。

​        

​         5.通用爬虫工作流程：爬取网页- 存储数据- 内容处理 - 提供检索- 排名服务

​         6.搜索引擎排名

​                1.pagerank值：根据网站的流量（点击量/浏览量/人气/)统计，流量越高，网站也越值钱。

​                2.竞价排名，广告

​        7.通用爬虫的缺点： 

​                    1.只能提供和文本相关的内容（HTML、Word、PDF）等等，但是不能提供多媒体文件（音乐、图片、视频）和二进制文件

​                    2.提供的结果千篇一律，不能针对不同背景领域的人提供不同给的搜索结果

​                    3.不能理解人类语义上的检索

为了解决这个问题、聚焦爬虫出现了

聚焦爬虫：爬虫程序员写的针对某种内容爬虫

面向主题爬虫，面向需求爬虫，会针对某种特定的内容去爬取信息。而且会保证内容信息和需求尽可能相关

​    
